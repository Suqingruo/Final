{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a957a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib, sys, os, random, time\n",
    "import cv2, gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "import torchvision\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34afe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE编码和解码函数\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(512, 512)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    if mask_rle == '' or pd.isna(mask_rle):\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "SEED = 42\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 384  # 增加图像尺寸以获取更多细节\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "THRESHOLD = 0.5  # 二值化阈值，可以通过验证集调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae901ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增强的数据增强策略\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.Normalize(\n",
    "        mean=[0.625, 0.448, 0.688],\n",
    "        std=[0.131, 0.177, 0.101],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.Normalize(\n",
    "        mean=[0.625, 0.448, 0.688],\n",
    "        std=[0.131, 0.177, 0.101],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingSegmentationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_paths, mask_paths=None, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 加载图像\n",
    "        img = cv2.imread(self.img_paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 加载mask (如果有)\n",
    "        if self.mask_paths is not None:\n",
    "            mask = np.load(self.mask_paths[idx])  # 假设这里加载了mask\n",
    "            \n",
    "            # 应用变换 (如果有)\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=img, mask=mask)\n",
    "                img = transformed['image']\n",
    "                mask = transformed['mask']\n",
    "            \n",
    "            # 类型转换安全处理\n",
    "            if isinstance(mask, np.ndarray):\n",
    "                mask_tensor = torch.from_numpy(mask).float()\n",
    "            elif isinstance(mask, torch.Tensor):\n",
    "                mask_tensor = mask.float()\n",
    "            else:\n",
    "                raise TypeError(f\"Unexpected mask type: {type(mask)}\")\n",
    "            \n",
    "            # 添加通道维度 (如果需要)\n",
    "            if mask_tensor.dim() == 2:\n",
    "                mask_tensor = mask_tensor.unsqueeze(0)\n",
    "            \n",
    "            return img, mask_tensor\n",
    "        else:\n",
    "            # 只返回图像的情况\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=img)\n",
    "                img = transformed['image']\n",
    "            \n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a092c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net模型定义 - 基础模块\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2D -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299417e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        factor = 2 if bilinear else 1\n",
    "        \n",
    "        # 使用更多滤波器以增加模型容量\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085bbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化的损失函数 - Dice Loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        \n",
    "        # 平滑处理以避免0/0的情况\n",
    "        intersection = (pred * target).sum(dim=(2,3))\n",
    "        union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "        \n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1.0 - dice.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化的损失函数 - Focal Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        \n",
    "        # 二元交叉熵损失\n",
    "        bce = F.binary_cross_entropy(pred, target, reduction='none')\n",
    "        \n",
    "        # 应用focal loss公式\n",
    "        pt = torch.exp(-bce)\n",
    "        focal_loss = (1-pt)**self.gamma * bce\n",
    "        \n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c43a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化的组合损失函数\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, dice_weight=0.5, focal_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.focal_loss = FocalLoss()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        focal = self.focal_loss(pred, target)\n",
    "        return self.dice_weight * dice + self.focal_weight * focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1f271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证函数\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    dice_scores = []\n",
    "    \n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # 计算Dice分数\n",
    "        preds = (torch.sigmoid(outputs) > THRESHOLD).float()\n",
    "        dice = (2 * (preds * masks).sum()) / (preds.sum() + masks.sum() + 1e-8)\n",
    "        dice_scores.append(dice.item())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader), np.mean(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d321106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "@torch.no_grad()\n",
    "def predict(model, dataloader, device, threshold=THRESHOLD):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    for images, filenames in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        \n",
    "        # 处理每个批次的预测\n",
    "        for pred, filename in zip(preds, filenames):\n",
    "            pred = pred.cpu().numpy().squeeze()\n",
    "            pred = cv2.resize(pred, (512, 512))  # 调整为原始大小\n",
    "            mask = (pred > threshold).astype(np.uint8)\n",
    "            rle = rle_encode(mask)\n",
    "            results.append([filename, rle])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主训练循环\n",
    "def main():\n",
    "    # 加载数据\n",
    "    # 确保这个路径正确指向您的train_mask.csv文件位置\n",
    "    train_mask = pd.read_csv('数据集/train_mask.csv', sep='\\t', names=['name', 'mask'])\n",
    "    # 确保这个路径前缀与您的训练图像目录一致\n",
    "    train_mask['name'] = train_mask['name'].apply(lambda x: '数据集/train/' + x)\n",
    "    \n",
    "    # 分割训练集和验证集\n",
    "    train_idx, valid_idx = [], []\n",
    "    for i in range(len(train_mask)):\n",
    "        if i % 7 == 0:\n",
    "            valid_idx.append(i)\n",
    "        else:\n",
    "            train_idx.append(i)\n",
    "    \n",
    "    train_df = train_mask.iloc[train_idx].reset_index(drop=True)\n",
    "    valid_df = train_mask.iloc[valid_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 创建数据集和数据加载器\n",
    "    train_ds = BuildingSegmentationDataset(\n",
    "        train_df['name'].values,\n",
    "        train_df['mask'].fillna('').values,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    valid_ds = BuildingSegmentationDataset(\n",
    "        valid_df['name'].values,\n",
    "        valid_df['mask'].fillna('').values,\n",
    "        transform=valid_transform\n",
    "    )\n",
    "    \n",
    "    train_loader = D.DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = D.DataLoader(\n",
    "        valid_ds, batch_size=BATCH_SIZE, shuffle=False, \n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=False)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # 优化器和学习率调度\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # 损失函数\n",
    "    criterion = CombinedLoss(dice_weight=0.7, focal_weight=0.3)\n",
    "    \n",
    "    # 训练循环\n",
    "    best_dice = 0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "        \n",
    "        # 训练\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, DEVICE)\n",
    "        \n",
    "        # 验证\n",
    "        val_loss, val_dice = validate(model, valid_loader, criterion, DEVICE)\n",
    "        \n",
    "        # 调整学习率\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f}\")\n",
    "        \n",
    "        # 保存最佳模型\n",
    "        if val_dice > best_dice:\n",
    "            print(f\"Dice improved from {best_dice:.4f} to {val_dice:.4f}. Saving model...\")\n",
    "            best_dice = val_dice\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), 'best_building_segmentation_model.pth')\n",
    "    \n",
    "    print(f\"Training complete! Best Dice: {best_dice:.4f} at epoch {best_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7673b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set():\n",
    "    # 加载最佳模型进行预测\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=False)\n",
    "    model.load_state_dict(torch.load('best_building_segmentation_model.pth'))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # 创建测试数据集\n",
    "    test_paths = []\n",
    "    # 确保这个路径指向您的测试图像目录\n",
    "    for file in os.listdir('数据集/test_a'):\n",
    "        if file.endswith('.jpg') or file.endswith('.tif'):\n",
    "            test_paths.append(os.path.join('数据集/test_a', file))\n",
    "    \n",
    "    test_ds = BuildingSegmentationDataset(\n",
    "        test_paths,\n",
    "        [\"\"] * len(test_paths),\n",
    "        transform=valid_transform,\n",
    "        test_mode=True\n",
    "    )\n",
    "    \n",
    "    test_loader = D.DataLoader(\n",
    "        test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # 预测并保存结果\n",
    "    results = predict(model, test_loader, DEVICE)\n",
    "    submission = pd.DataFrame(results, columns=['name', 'mask'])\n",
    "    submission.to_csv('submission.csv', index=False, header=False, sep='\\t')\n",
    "    print(\"Prediction complete! Results saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb485e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    predict_test_set()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
