{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a957a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib, sys, os, random, time\n",
    "import cv2, gc\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import rasterio\n",
    "from rasterio.windows import Window\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "import torchvision\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b34afe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RLE编码和解码函数\n",
    "def rle_encode(im):\n",
    "    '''\n",
    "    im: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formated\n",
    "    '''\n",
    "    pixels = im.flatten(order = 'F')\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_decode(mask_rle, shape=(512, 512)):\n",
    "    '''\n",
    "    mask_rle: run-length as string formated (start length)\n",
    "    shape: (height,width) of array to return \n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "    '''\n",
    "    if mask_rle == '' or pd.isna(mask_rle):\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "    \n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置参数\n",
    "SEED = 42\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_SIZE = 384  # 增加图像尺寸以获取更多细节\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "THRESHOLD = 0.5  # 二值化阈值，可以通过验证集调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae901ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 增强的数据增强策略\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.ShiftScaleRotate(p=0.5, shift_limit=0.1, scale_limit=0.2, rotate_limit=30),\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(p=1.0),\n",
    "        A.RandomGamma(p=1.0),\n",
    "        A.HueSaturationValue(p=1.0)\n",
    "    ], p=0.5),\n",
    "    A.OneOf([\n",
    "        A.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03, p=1.0),\n",
    "        A.GridDistortion(p=1.0),\n",
    "        A.OpticalDistortion(distort_limit=1.0, shift_limit=0.5, p=1.0),\n",
    "    ], p=0.3),\n",
    "    A.CoarseDropout(max_holes=8, max_height=32, max_width=32, p=0.3),\n",
    "    A.GaussNoise(p=0.3),\n",
    "    A.Normalize(\n",
    "        mean=[0.625, 0.448, 0.688],\n",
    "        std=[0.131, 0.177, 0.101],\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e6f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingSegmentationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_paths, mask_paths=None, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 加载图像\n",
    "        img = cv2.imread(self.img_paths[idx])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 处理掩码数据\n",
    "        if self.mask_paths is not None:\n",
    "            mask_data = self.mask_paths[idx]\n",
    "            \n",
    "            # 使用已有的rle_decode函数处理RLE格式的掩码\n",
    "            if isinstance(mask_data, str):\n",
    "                mask = rle_decode(mask_data, shape=(512, 512))\n",
    "            elif isinstance(mask_data, np.ndarray):\n",
    "                mask = mask_data\n",
    "            elif isinstance(mask_data, torch.Tensor):\n",
    "                mask = mask_data.cpu().numpy()\n",
    "            else:\n",
    "                print(f\"警告：未知的掩码数据类型 - {type(mask_data)}\")\n",
    "                mask = np.zeros((512, 512), dtype=np.uint8)\n",
    "            \n",
    "            # 应用变换\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=img, mask=mask)\n",
    "                img = transformed[\"image\"]\n",
    "                mask = transformed[\"mask\"]\n",
    "            \n",
    "            # 关键修复: 始终确保mask是float类型的tensor\n",
    "            if isinstance(mask, np.ndarray):\n",
    "                mask = torch.from_numpy(mask).float()\n",
    "            else:\n",
    "                # 确保tensor是float类型\n",
    "                mask = mask.float()\n",
    "            \n",
    "            if mask.dim() == 2:\n",
    "                mask = mask.unsqueeze(0)\n",
    "                \n",
    "            return img, mask\n",
    "        else:\n",
    "            # 只返回图像（用于测试集）\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=img)\n",
    "                img = transformed[\"image\"]\n",
    "                \n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a092c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U-Net模型定义 - 基础模块\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2D -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733d9acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "299417e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        factor = 2 if bilinear else 1\n",
    "        \n",
    "        # 使用更多滤波器以增加模型容量\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085bbf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化的损失函数 - Dice Loss\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        \n",
    "        # 平滑处理以避免0/0的情况\n",
    "        intersection = (pred * target).sum(dim=(2,3))\n",
    "        union = pred.sum(dim=(2,3)) + target.sum(dim=(2,3))\n",
    "        \n",
    "        dice = (2.0 * intersection + self.smooth) / (union + self.smooth)\n",
    "        return 1.0 - dice.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031b991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = 1e-7  # 添加极小值避免数值不稳定\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        # 确保输入是float类型\n",
    "        pred = torch.sigmoid(pred)\n",
    "        target = target.float()  # 确保target也是float\n",
    "        \n",
    "        # 二元交叉熵损失\n",
    "        bce = F.binary_cross_entropy(pred + self.eps, target, reduction='none')\n",
    "        \n",
    "        # 应用focal loss公式\n",
    "        pt = torch.exp(-bce)\n",
    "        focal_loss = (1-pt)**self.gamma * bce\n",
    "        \n",
    "        return focal_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c43a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化的组合损失函数\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, dice_weight=0.5, focal_weight=0.5):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.dice_weight = dice_weight\n",
    "        self.focal_weight = focal_weight\n",
    "        self.dice_loss = DiceLoss()\n",
    "        self.focal_loss = FocalLoss()\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        focal = self.focal_loss(pred, target)\n",
    "        return self.dice_weight * dice + self.focal_weight * focal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1422949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"当验证集性能不再提升时提前停止训练\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): 验证集性能不提升后等待多少轮停止训练\n",
    "            verbose (bool): 是否打印详细信息\n",
    "            delta (float): 性能变化的最小阈值\n",
    "            path (str): 保存检查点路径\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        \n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'早停计数: {self.counter}/{self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "            \n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''当验证损失减小时保存模型'''\n",
    "        if self.verbose:\n",
    "            print(f'验证损失从 ({self.val_loss_min:.6f} 降至 {val_loss:.6f})。保存模型...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a082a9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练函数\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e1f271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 验证函数\n",
    "@torch.no_grad()\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    dice_scores = []\n",
    "    \n",
    "    for images, masks in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # 计算Dice分数\n",
    "        preds = (torch.sigmoid(outputs) > THRESHOLD).float()\n",
    "        dice = (2 * (preds * masks).sum()) / (preds.sum() + masks.sum() + 1e-8)\n",
    "        dice_scores.append(dice.item())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader), np.mean(dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d321106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测函数\n",
    "@torch.no_grad()\n",
    "def predict(model, dataloader, device, threshold=THRESHOLD):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    \n",
    "    for images, filenames in tqdm(dataloader):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.sigmoid(outputs)\n",
    "        \n",
    "        # 处理每个批次的预测\n",
    "        for pred, filename in zip(preds, filenames):\n",
    "            pred = pred.cpu().numpy().squeeze()\n",
    "            pred = cv2.resize(pred, (512, 512))  # 调整为原始大小\n",
    "            mask = (pred > threshold).astype(np.uint8)\n",
    "            rle = rle_encode(mask)\n",
    "            results.append([filename, rle])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344ff872",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_with_tta(model, image, device, threshold=THRESHOLD, tta_transforms=None):\n",
    "    \"\"\"测试时增强提高预测质量\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 如果没有提供TTA变换，则使用基本变换\n",
    "    if tta_transforms is None:\n",
    "        tta_transforms = [\n",
    "            A.Compose([A.Normalize(mean=[0.625, 0.448, 0.688], std=[0.131, 0.177, 0.101]), ToTensorV2()]),\n",
    "            A.Compose([A.HorizontalFlip(p=1.0), A.Normalize(mean=[0.625, 0.448, 0.688], std=[0.131, 0.177, 0.101]), ToTensorV2()]),\n",
    "            A.Compose([A.VerticalFlip(p=1.0), A.Normalize(mean=[0.625, 0.448, 0.688], std=[0.131, 0.177, 0.101]), ToTensorV2()]),\n",
    "            A.Compose([A.Transpose(p=1.0), A.Normalize(mean=[0.625, 0.448, 0.688], std=[0.131, 0.177, 0.101]), ToTensorV2()])\n",
    "        ]\n",
    "    \n",
    "    # 应用所有变换并预测\n",
    "    preds = []\n",
    "    for transform in tta_transforms:\n",
    "        augmented = transform(image=image)\n",
    "        img_tensor = augmented['image'].unsqueeze(0).to(device)\n",
    "        output = model(img_tensor)\n",
    "        pred = torch.sigmoid(output).cpu().numpy().squeeze()\n",
    "        \n",
    "        # 还原变换\n",
    "        if 'HorizontalFlip' in str(transform):\n",
    "            pred = np.fliplr(pred)\n",
    "        if 'VerticalFlip' in str(transform):\n",
    "            pred = np.flipud(pred)\n",
    "        if 'Transpose' in str(transform):\n",
    "            pred = np.transpose(pred)\n",
    "            \n",
    "        preds.append(pred)\n",
    "    \n",
    "    # 平均所有预测结果\n",
    "    final_pred = np.mean(preds, axis=0)\n",
    "    return (final_pred > threshold).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b5fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # 设置随机种子\n",
    "    seed_everything(SEED)\n",
    "    \n",
    "    # 加载数据\n",
    "    try:\n",
    "        print(\"正在加载训练数据...\")\n",
    "        train_mask = pd.read_csv('数据集/train_mask.csv', sep='\\t', names=['name', 'mask'])\n",
    "        train_mask['name'] = train_mask['name'].apply(lambda x: '数据集/train/' + x)\n",
    "    except Exception as e:\n",
    "        print(f\"加载数据时出错: {e}\")\n",
    "        print(\"请确保'数据集/train_mask.csv'文件存在并且格式正确!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"已加载 {len(train_mask)} 条训练数据\")\n",
    "    \n",
    "    # 分割训练集和验证集\n",
    "    train_idx, valid_idx = [], []\n",
    "    for i in range(len(train_mask)):\n",
    "        if i % 7 == 0:\n",
    "            valid_idx.append(i)\n",
    "        else:\n",
    "            train_idx.append(i)\n",
    "    \n",
    "    train_df = train_mask.iloc[train_idx].reset_index(drop=True)\n",
    "    valid_df = train_mask.iloc[valid_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"训练集: {len(train_df)} 样本, 验证集: {len(valid_df)} 样本\")\n",
    "    \n",
    "    # 创建数据集和数据加载器\n",
    "    train_ds = BuildingSegmentationDataset(\n",
    "        train_df['name'].values,\n",
    "        train_df['mask'].fillna('').values,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    valid_ds = BuildingSegmentationDataset(\n",
    "        valid_df['name'].values,\n",
    "        valid_df['mask'].fillna('').values,\n",
    "        transform=valid_transform\n",
    "    )\n",
    "    \n",
    "    train_loader = D.DataLoader(\n",
    "        train_ds, batch_size=BATCH_SIZE, shuffle=True, \n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    valid_loader = D.DataLoader(\n",
    "        valid_ds, batch_size=BATCH_SIZE, shuffle=False, \n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=False)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # 打印模型摘要\n",
    "    print(f\"模型已创建并加载到设备: {DEVICE}\")\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"模型总参数量: {total_params:,}\")\n",
    "    \n",
    "    # 优化器和学习率调度\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=3, verbose=True\n",
    "    )\n",
    "    \n",
    "    # 损失函数\n",
    "    criterion = CombinedLoss(dice_weight=0.7, focal_weight=0.3)\n",
    "    \n",
    "    # 使用改进的训练循环\n",
    "    best_dice, best_epoch = train_with_checkpoints(\n",
    "        model, train_loader, valid_loader, optimizer, \n",
    "        criterion, scheduler, DEVICE, EPOCHS, checkpoint_dir='model_checkpoints'\n",
    "    )\n",
    "    \n",
    "    print(f\"训练完成! 最佳Dice分数: {best_dice:.4f} 在第{best_epoch}轮\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7673b684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_test_set():\n",
    "    # 加载最佳模型进行预测\n",
    "    model = UNet(n_channels=3, n_classes=1, bilinear=False)\n",
    "    model.load_state_dict(torch.load('best_building_segmentation_model.pth'))\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    # 创建测试数据集\n",
    "    test_paths = []\n",
    "    # 确保这个路径指向您的测试图像目录\n",
    "    for file in os.listdir('数据集/test_a'):\n",
    "        if file.endswith('.jpg') or file.endswith('.tif'):\n",
    "            test_paths.append(os.path.join('数据集/test_a', file))\n",
    "    \n",
    "    # 确保使用的是正确的BuildingSegmentationDataset类\n",
    "    test_ds = BuildingSegmentationDataset(\n",
    "        test_paths,\n",
    "        None,  # 测试集没有掩码数据\n",
    "        transform=valid_transform\n",
    "    )\n",
    "    \n",
    "    test_loader = D.DataLoader(\n",
    "        test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "        num_workers=4, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # 修改predict函数的调用，因为测试集没有文件名\n",
    "    model.eval()\n",
    "    results = []\n",
    "    test_files = [os.path.basename(p) for p in test_paths]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for images in tqdm(test_loader):\n",
    "            images = images.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            \n",
    "            # 处理每个批次的预测\n",
    "            for pred in preds:\n",
    "                if i >= len(test_files):  # 安全检查\n",
    "                    break\n",
    "                    \n",
    "                pred = pred.cpu().numpy().squeeze()\n",
    "                pred = cv2.resize(pred, (512, 512))  # 调整为原始大小\n",
    "                mask = (pred > THRESHOLD).astype(np.uint8)\n",
    "                rle = rle_encode(mask)\n",
    "                results.append([test_files[i], rle])\n",
    "                i += 1\n",
    "    \n",
    "    submission = pd.DataFrame(results, columns=['name', 'mask'])\n",
    "    submission.to_csv('submission.csv', index=False, header=False, sep='\\t')\n",
    "    print(\"Prediction complete! Results saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afb485e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14839eefa41c4262941c85edb10e15ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6429 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found dtype Byte but expected Float",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     predict_test_set()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# 训练\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m train_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# 验证\u001b[39;00m\n\u001b[32m     67\u001b[39m val_loss, val_dice = validate(model, valid_loader, criterion, DEVICE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(model, dataloader, optimizer, criterion, device)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 前向传播\u001b[39;00m\n\u001b[32m     11\u001b[39m outputs = model(images)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 反向传播和优化\u001b[39;00m\n\u001b[32m     15\u001b[39m optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mCombinedLoss.forward\u001b[39m\u001b[34m(self, pred, target)\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pred, target):\n\u001b[32m     11\u001b[39m     dice = \u001b[38;5;28mself\u001b[39m.dice_loss(pred, target)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     focal = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfocal_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dice_weight * dice + \u001b[38;5;28mself\u001b[39m.focal_weight * focal\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mFocalLoss.forward\u001b[39m\u001b[34m(self, pred, target)\u001b[39m\n\u001b[32m      8\u001b[39m pred = torch.sigmoid(pred)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 二元交叉熵损失\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m bce = \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnone\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# 应用focal loss公式\u001b[39;00m\n\u001b[32m     14\u001b[39m pt = torch.exp(-bce)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/nn/functional.py:3554\u001b[39m, in \u001b[36mbinary_cross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, reduce, reduction)\u001b[39m\n\u001b[32m   3551\u001b[39m     new_size = _infer_size(target.size(), weight.size())\n\u001b[32m   3552\u001b[39m     weight = weight.expand(new_size)\n\u001b[32m-> \u001b[39m\u001b[32m3554\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Found dtype Byte but expected Float"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    predict_test_set()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
